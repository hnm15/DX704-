{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Md413FzAvFD8"
      },
      "source": [
        "# DX 704 Week 4 Project\n",
        "\n",
        "This week's project will test the learning speed of linear contextual bandits compared to unoptimized approaches.\n",
        "You will start with building a preference data set for evaluation, and then implement different variations of LinUCB and visualize how fast they learn the preferences.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3gs-tquuzJe"
      },
      "source": [
        "The full project description, a template notebook and supporting code are available on GitHub: [Project 4 Materials](https://github.com/bu-cds-dx704/dx704-project-04).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OguIjc5idW3Z"
      },
      "source": [
        "## Example Code\n",
        "\n",
        "You may find it helpful to refer to these GitHub repositories of Jupyter notebooks for example code.\n",
        "\n",
        "* https://github.com/bu-cds-omds/dx601-examples\n",
        "* https://github.com/bu-cds-omds/dx602-examples\n",
        "* https://github.com/bu-cds-omds/dx603-examples\n",
        "* https://github.com/bu-cds-omds/dx704-examples\n",
        "\n",
        "Any calculations demonstrated in code examples or videos may be found in these notebooks, and you are allowed to copy this example code in your homework answers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8oSLkMqvMFF"
      },
      "source": [
        "## Part 1: Collect Rating Data\n",
        "\n",
        "The file \"recipes.tsv\" in this repository has information about 100 recipes.\n",
        "Make a new file \"ratings.tsv\" with two columns, recipe_slug (from recipes.tsv) and rating.\n",
        "Populate the rating column with values between 0 and 1 where 0 is the worst and 1 is the best.\n",
        "You can assign these ratings however you want within that range, but try to make it reflect a consistent set of preferences.\n",
        "These could be your preferences, or a persona of your choosing (e.g. chocolate lover, bacon-obsessed, or sweet tooth).\n",
        "Make sure that there are at least 10 ratings of zero and at least 10 ratings of one.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAwViBgKfWER"
      },
      "source": [
        "Hint: You may find it more convenient to assign raw ratings from 1 to 5 and then remap them as follows.\n",
        "\n",
        "`ratings[\"rating\"] = (ratings[\"rating_raw\"] - 1) * 0.25`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eh7UaX6OvuWo"
      },
      "source": [
        "Submit \"ratings.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created ratings.tsv with 100 recipes\n",
            "Ratings of 0.0: 10\n",
            "Ratings of 1.0: 10\n",
            "\n",
            "Distribution:\n",
            "rating\n",
            "0.00    10\n",
            "0.25     6\n",
            "0.50    60\n",
            "0.75    14\n",
            "1.00    10\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "recipes = pd.read_csv('recipes.tsv', sep='\\t')\n",
        "\n",
        "ratings = pd.DataFrame()\n",
        "ratings['recipe_slug'] = recipes['recipe_slug']\n",
        "\n",
        "def rate_recipe(row):\n",
        "    title = str(row.get('recipe_title', '')).lower()\n",
        "    intro = str(row.get('recipe_introduction', '')).lower()\n",
        "    text = title + ' ' + intro\n",
        "\n",
        "    if ('bacon' in text and 'chocolate' in text) or \\\n",
        "       any(word in text for word in ['chocolate cake', 'chocolate souffle', 'brownies', \n",
        "                                      'chocolate babka', 'pain au chocolat', 'chocolate croissant']):\n",
        "        return 5\n",
        "\n",
        "    if 'bacon' in text or ('peanut butter' in text and 'chocolate' in text):\n",
        "        return 4\n",
        "\n",
        "    if any(word in text for word in ['pasta', 'lasagna', 'taco', 'burrito', 'enchilada', \n",
        "                                      'nacho', 'quesadilla', 'noodle', 'crisp', 'crumble']):\n",
        "        return 3\n",
        "\n",
        "    if any(word in text for word in ['quiche', 'soup', 'salad', 'pickled', 'relish']):\n",
        "        return 2\n",
        "\n",
        "    if any(word in text for word in ['oyster', 'spam', 'falafel', 'asparagus', \n",
        "                                      'mushroom', 'spinach', 'vegetarian', 'cold noodles']):\n",
        "        return 1\n",
        "\n",
        "    return 3\n",
        "\n",
        "ratings['rating_raw'] = recipes.apply(rate_recipe, axis=1)\n",
        "\n",
        "ratings['rating'] = (ratings['rating_raw'] - 1) * 0.25\n",
        "\n",
        "num_zeros = (ratings['rating'] == 0.0).sum()\n",
        "if num_zeros < 10:\n",
        "    needed = 10 - num_zeros\n",
        "    candidates = ratings[ratings['rating'] > 0.0].head(needed).index\n",
        "    ratings.loc[candidates, 'rating'] = 0.0\n",
        "\n",
        "num_ones = (ratings['rating'] == 1.0).sum()\n",
        "if num_ones < 10:\n",
        "    needed = 10 - num_ones\n",
        "    candidates = ratings[ratings['rating'] < 1.0].tail(needed).index\n",
        "    ratings.loc[candidates, 'rating'] = 1.0\n",
        "\n",
        "ratings = ratings[['recipe_slug', 'rating']]\n",
        "\n",
        "ratings.to_csv('ratings.tsv', sep='\\t', index=False)\n",
        "\n",
        "print(f\"Created ratings.tsv with {len(ratings)} recipes\")\n",
        "print(f\"Ratings of 0.0: {(ratings['rating'] == 0.0).sum()}\")\n",
        "print(f\"Ratings of 1.0: {(ratings['rating'] == 1.0).sum()}\")\n",
        "print(f\"\\nDistribution:\")\n",
        "print(ratings['rating'].value_counts().sort_index())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiCwaZwr5M67"
      },
      "source": [
        "## Part 2: Construct Model Input\n",
        "\n",
        "Use your file \"ratings.tsv\" combined with \"recipe-tags.tsv\" to create a new file \"features.tsv\" with a column recipe_slug, a column bias which is hard-coded to one, and a column for each tag that appears in \"recipe-tags.tsv\".\n",
        "The tag column in this file should be a 0-1 encoding of the recipe tags for each recipe.\n",
        "[Pandas reshaping function methods](https://pandas.pydata.org/docs/user_guide/reshaping.html) may be helpful."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WWi_JJXocEb"
      },
      "source": [
        "The bias column will make later LinUCB calculations easier since it will just be another dimension."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHR-BsD9539j"
      },
      "source": [
        "Hint: For later modeling steps, it will be important to have the feature data (inputs) and the rating data (target outputs) in the same order.\n",
        "It is highly recommended to make sure that \"features.tsv\" and \"ratings.tsv\" have the recipe slugs in the same order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "cGvj258d8nnv"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created features.tsv with 100 recipes\n",
            "Number of tag columns: 296\n",
            "\n",
            "First few columns: ['recipe_slug', 'bias', 'alfredo', 'almond', 'american']\n",
            "\n",
            "Verifying order matches ratings.tsv: True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_5662/2815755130.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  features.insert(1, 'bias', 1)\n"
          ]
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "ratings = pd.read_csv('ratings.tsv', sep='\\t')\n",
        "recipe_tags = pd.read_csv('recipe-tags.tsv', sep='\\t')\n",
        "\n",
        "features = recipe_tags.pivot_table(\n",
        "    index='recipe_slug',\n",
        "    columns='recipe_tag',\n",
        "    aggfunc=len,\n",
        "    fill_value=0\n",
        ").reset_index()\n",
        "\n",
        "tag_columns = [col for col in features.columns if col != 'recipe_slug']\n",
        "for col in tag_columns:\n",
        "    features[col] = (features[col] > 0).astype(int)\n",
        "\n",
        "features.insert(1, 'bias', 1)\n",
        "\n",
        "all_recipes = pd.DataFrame({'recipe_slug': ratings['recipe_slug']})\n",
        "features = all_recipes.merge(features, on='recipe_slug', how='left')\n",
        "\n",
        "features = features.fillna(0)\n",
        "\n",
        "for col in features.columns:\n",
        "    if col not in ['recipe_slug', 'bias']:\n",
        "        features[col] = features[col].astype(int)\n",
        "\n",
        "features = features.set_index('recipe_slug').loc[ratings['recipe_slug']].reset_index()\n",
        "\n",
        "features.to_csv('features.tsv', sep='\\t', index=False)\n",
        "\n",
        "print(f\"Created features.tsv with {len(features)} recipes\")\n",
        "print(f\"Number of tag columns: {len(features.columns) - 2}\")\n",
        "print(f\"\\nFirst few columns: {list(features.columns[:5])}\")\n",
        "print(f\"\\nVerifying order matches ratings.tsv: {(features['recipe_slug'] == ratings['recipe_slug']).all()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w63ji-Oi6oH7"
      },
      "source": [
        "Submit \"features.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TeXvznlwJzo"
      },
      "source": [
        "## Part 3: Linear Preference Model\n",
        "\n",
        "Use your feature and rating files to build a ridge regression model with ridge regression's regularization parameter $\\alpha$ set to 1.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVlUnVv4oDIk"
      },
      "source": [
        "Hint: If you are using scikit-learn modeling classes, you should use `fit_intercept=False` since that intercept value will be redundant with the bias coefficient."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLrBu-z7A45W"
      },
      "source": [
        "Hint: The estimate component of the bounds should match the previous estimate, so you should be able to just focus on the variance component of the bounds now."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "dxtiRunPwPYz"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ridge coefficients (including bias):\n",
            "[ 3.61673203e-01 -4.54731138e-02  3.70314126e-02 -7.87947834e-03\n",
            "  9.79271317e-03 -4.37892450e-03 -8.89362289e-02  3.80169129e-02\n",
            "  3.91288792e-02  1.90180516e-02  1.46451091e-01 -2.20809792e-03\n",
            " -2.53883905e-02 -3.70824971e-02  6.93697879e-02  1.91052055e-02\n",
            "  2.40566415e-02  2.30902078e-03  3.59702811e-02  2.30902078e-03\n",
            " -5.96404279e-05 -1.28361183e-03  5.21810876e-03  5.21810876e-03\n",
            "  2.03594366e-02 -3.74817142e-02  4.92922944e-02  5.55725769e-02\n",
            "  5.16789855e-02 -8.92865042e-02  3.57470053e-02  1.22780668e-01\n",
            " -2.78592418e-03  4.26428391e-02  3.07640450e-02  4.08432745e-02\n",
            "  6.08548757e-02  5.64721657e-02  5.21810876e-03  5.37232545e-04\n",
            "  1.10964360e-02  2.02237958e-02  1.08046456e-01 -2.17247042e-02\n",
            " -3.78511530e-02  3.07640450e-02  1.32502412e-02  2.30902078e-03\n",
            "  2.60300244e-02  1.33098816e-02  1.29302592e-02  1.69099634e-01\n",
            "  7.12716094e-02  5.16789855e-02 -2.02396649e-03  1.81450706e-02\n",
            "  3.06713280e-02 -4.26786499e-02  4.40870021e-02  4.23216708e-03\n",
            " -7.63177042e-03  1.03956613e-01 -3.42544449e-03  2.60300244e-02\n",
            "  3.48565575e-02  1.17762522e-02  3.80526679e-02 -2.12031543e-01\n",
            "  1.10964360e-02 -3.64589103e-02 -7.17715658e-03  1.33059916e-02\n",
            " -7.13633280e-02  2.28851535e-02 -3.42544449e-03  9.55512161e-02\n",
            " -4.83468614e-02  4.23216708e-03  3.48565575e-02  2.30902078e-03\n",
            " -2.24141019e-02 -2.61479931e-02 -7.99738618e-03  1.81753599e-02\n",
            " -7.17715658e-03  1.74543971e-02  3.84437996e-02  7.83601273e-02\n",
            "  1.01413920e-01 -6.25618160e-02  1.18306723e-02  1.30597696e-02\n",
            "  2.03594366e-02  5.10046044e-02 -8.25515550e-03  4.15198332e-02\n",
            " -4.20020776e-02 -2.33948528e-02 -1.35307080e-03 -1.24817416e-01\n",
            " -7.71792295e-03  4.92922944e-02 -2.22061847e-02 -3.63890699e-02\n",
            " -9.13466783e-02 -1.62182639e-02  3.03325082e-02  9.57669041e-02\n",
            "  1.11710439e-02  5.50920529e-02 -8.24598823e-02  3.46753941e-02\n",
            " -5.45644298e-02  4.86661227e-03  3.40580637e-02 -1.03146355e-03\n",
            "  5.80006907e-02  1.83904839e-02 -4.74844469e-02  2.61991878e-02\n",
            "  1.33098816e-02  5.65493032e-02  2.25797049e-02 -2.97648917e-02\n",
            "  1.28893062e-02  4.60613833e-02  3.07640450e-02  8.04122820e-03\n",
            "  3.57470053e-02  1.05729774e-01 -3.59815110e-02  2.39873979e-02\n",
            "  2.00611555e-02 -7.17715658e-03 -4.04054984e-02  1.81753599e-02\n",
            " -4.43493405e-02 -4.04054984e-02 -4.11398867e-02 -4.32577334e-02\n",
            "  3.02016130e-02  9.07246947e-03  1.41280280e-02 -2.24141019e-02\n",
            "  1.02170413e-01 -4.54731138e-02  4.86661227e-03  5.67329559e-02\n",
            "  6.49395373e-02 -4.04054984e-02  6.43919160e-03 -9.13466783e-02\n",
            " -4.43493405e-02 -3.70824971e-02  1.99839991e-01  4.23216708e-03\n",
            " -1.28704302e-02  4.83518904e-03  1.35238716e-02  6.43919160e-03\n",
            " -6.25618160e-02  2.13033778e-02  1.30597696e-02  3.26501300e-02\n",
            "  1.10964360e-02 -4.04054984e-02  4.92922944e-02  4.64155918e-02\n",
            " -3.77557042e-02 -2.29803702e-02  6.91851822e-02  1.99121475e-02\n",
            "  1.35238716e-02 -9.72096787e-02  5.21810876e-03  4.64155918e-02\n",
            "  1.20692921e-01  5.21810876e-03  2.47804678e-02  6.00308340e-02\n",
            "  5.21810876e-03 -4.11398867e-02  2.62997813e-02  1.44624290e-03\n",
            " -1.15905286e-02  3.16490196e-02  1.70446628e-02  9.55949985e-04\n",
            " -4.11398867e-02  5.16789855e-02  1.35035744e-02 -4.04054984e-02\n",
            "  3.26501300e-02 -3.59815110e-02  5.89631544e-02  1.00981047e-01\n",
            " -2.29803702e-02  1.10803890e-02  3.19847841e-02  2.03414834e-02\n",
            "  5.28821189e-02  1.60496616e-02 -5.96404279e-05 -1.35307080e-03\n",
            "  6.89867538e-03 -3.64731126e-03 -2.22061847e-02 -5.96404279e-05\n",
            "  5.21810876e-03  4.08432745e-02  4.64155918e-02  5.16789855e-02\n",
            " -1.31444226e-01  2.50038386e-02  5.21810876e-03  2.28444152e-02\n",
            " -4.26786499e-02  2.28444152e-02 -4.11398867e-02  1.28893062e-02\n",
            "  7.83601273e-02  1.16622798e-01 -5.31520738e-04  3.13416822e-02\n",
            "  2.13033778e-02  4.15198332e-02  4.06546834e-02 -1.39155873e-02\n",
            "  1.32502412e-02  4.84467266e-02  5.33479659e-02  2.60300244e-02\n",
            "  1.28893062e-02  1.28893062e-02  3.57470053e-02  2.62401408e-02\n",
            "  1.32502412e-02  4.10787922e-02 -2.97648917e-02  3.57470053e-02\n",
            "  3.16784853e-02 -3.32884984e-02 -2.48982794e-02  3.80169129e-02\n",
            "  2.25797049e-02  1.02912919e-01 -1.02888905e-02  2.05560592e-02\n",
            "  6.21345545e-03  1.35035744e-02 -2.32067737e-02 -8.15453851e-02\n",
            "  3.02016130e-02  2.28201744e-02  2.11718197e-02  2.79138830e-02\n",
            " -1.46695586e-01  1.10964360e-02  1.29898997e-02  2.28444152e-02\n",
            " -8.50002049e-02  2.11718197e-02  9.70552380e-03 -4.11398867e-02\n",
            " -5.21547888e-02 -2.83303153e-01  4.57098996e-02  4.82535410e-02\n",
            " -1.54384504e-02  1.22094737e-02  2.08204487e-02  4.06546834e-02\n",
            " -3.42544449e-03  1.74543971e-02  7.18719992e-02 -1.35307080e-03\n",
            " -2.02396649e-03  4.15198332e-02  2.93704606e-02  1.17473614e-03\n",
            "  9.33212418e-02  2.30902078e-03 -1.54384504e-02 -1.14273194e-03\n",
            "  3.94902037e-02  1.10964360e-02  2.03594366e-02  1.74543971e-02\n",
            " -2.33948528e-02  3.16490196e-02 -3.29337210e-02 -2.45609356e-01\n",
            " -2.58241350e-02  5.16789855e-02  3.16490196e-02 -1.24817416e-01\n",
            "  2.03594366e-02]\n",
            "\n",
            "First 10 predicted ratings:\n",
            "[0.09720968 0.0404055  0.05456443 0.09134668 0.09038247 0.03443494\n",
            " 0.28330315 0.04434934 0.14669559 0.49478189]\n"
          ]
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "features = pd.read_csv('features.tsv', sep='\\t')\n",
        "ratings = pd.read_csv('ratings.tsv', sep='\\t')\n",
        "\n",
        "assert (features['recipe_slug'] == ratings['recipe_slug']).all(), \"Recipe slugs must be aligned!\"\n",
        "\n",
        "X = features.drop(columns='recipe_slug').values \n",
        "y = ratings['rating'].values\n",
        "\n",
        "ridge_model = Ridge(alpha=1.0, fit_intercept=False)\n",
        "ridge_model.fit(X, y)\n",
        "\n",
        "coef = ridge_model.coef_\n",
        "print(\"Ridge coefficients (including bias):\")\n",
        "print(coef)\n",
        "\n",
        "y_pred = ridge_model.predict(X)\n",
        "print(\"\\nFirst 10 predicted ratings:\")\n",
        "print(y_pred[:10])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fw9LaHF_8tsA"
      },
      "source": [
        "Save the coefficients of this model in a file \"model.tsv\" with columns \"recipe_tag\" and \"coefficient\".\n",
        "Do not add anything for the `intercept_` attribute of a scikit-learn model; this will be covered by the coefficient for the bias column added in part 2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "fiMBlU4L8uSR"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved ridge coefficients to model.tsv with 297 rows\n",
            "  recipe_tag  coefficient\n",
            "0       bias     0.361673\n",
            "1    alfredo    -0.045473\n",
            "2     almond     0.037031\n",
            "3   american    -0.007879\n",
            "4  appetizer     0.009793\n"
          ]
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "features = pd.read_csv('features.tsv', sep='\\t')\n",
        "ratings = pd.read_csv('ratings.tsv', sep='\\t')\n",
        "\n",
        "assert (features['recipe_slug'] == ratings['recipe_slug']).all(), \"Recipe slugs must be aligned!\"\n",
        "\n",
        "X = features.drop(columns='recipe_slug').values\n",
        "y = ratings['rating'].values\n",
        "\n",
        "ridge_model = Ridge(alpha=1.0, fit_intercept=False)\n",
        "ridge_model.fit(X, y)\n",
        "\n",
        "feature_names = features.drop(columns='recipe_slug').columns\n",
        "\n",
        "coef_df = pd.DataFrame({\n",
        "    'recipe_tag': feature_names,\n",
        "    'coefficient': ridge_model.coef_\n",
        "})\n",
        "\n",
        "coef_df.to_csv('model.tsv', sep='\\t', index=False)\n",
        "\n",
        "print(f\"Saved ridge coefficients to model.tsv with {len(coef_df)} rows\")\n",
        "print(coef_df.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86uS_zZ0wQxC"
      },
      "source": [
        "Submit \"model.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1Nfs7zCsDpj"
      },
      "source": [
        "## Part 4: Recipe Estimates\n",
        "\n",
        "Use the recipe model to estimate the score of every recipe.\n",
        "Save these estimates to a file \"estimates.tsv\" with columns recipe_slug and score_estimate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "pIClPwYVso5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved score estimates to estimates.tsv with 100 recipes\n",
            "\n",
            "First 10 estimates:\n",
            "                    recipe_slug  score_estimate\n",
            "0                       falafel        0.097210\n",
            "1                    spamburger        0.040405\n",
            "2              bacon-fried-rice        0.054564\n",
            "3               chicken-fingers        0.091347\n",
            "4                   apple-crisp        0.090382\n",
            "5         cranberry-apple-crisp        0.034435\n",
            "6  bacon-chocolate-chip-cookies        0.283303\n",
            "7                        sujebi        0.044349\n",
            "8               pasta-primavera        0.146696\n",
            "9                         ramen        0.494782\n",
            "\n",
            "Estimate statistics:\n",
            "count    100.000000\n",
            "mean       0.516383\n",
            "std        0.209628\n",
            "min        0.034435\n",
            "25%        0.473171\n",
            "50%        0.497139\n",
            "75%        0.575325\n",
            "max        0.979641\n",
            "Name: score_estimate, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "\n",
        "features = pd.read_csv('features.tsv', sep='\\t')\n",
        "model = pd.read_csv('model.tsv', sep='\\t')\n",
        "\n",
        "X = features.drop(columns='recipe_slug').values\n",
        "\n",
        "coefficients = model['coefficient'].values\n",
        "\n",
        "score_estimates = X @ coefficients\n",
        "\n",
        "estimates = pd.DataFrame({\n",
        "    'recipe_slug': features['recipe_slug'],\n",
        "    'score_estimate': score_estimates\n",
        "})\n",
        "\n",
        "estimates.to_csv('estimates.tsv', sep='\\t', index=False)\n",
        "\n",
        "print(f\"Saved score estimates to estimates.tsv with {len(estimates)} recipes\")\n",
        "print(f\"\\nFirst 10 estimates:\")\n",
        "print(estimates.head(10))\n",
        "print(f\"\\nEstimate statistics:\")\n",
        "print(estimates['score_estimate'].describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5t3uSE_srMA"
      },
      "source": [
        "Submit \"estimates.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTBplNhRst8q"
      },
      "source": [
        "## Part 5: LinUCB Bounds\n",
        "\n",
        "Calculate the upper bounds of LinUCB using data corresponding to trying every recipe once and receiving the rating in \"ratings.tsv\" as the reward.\n",
        "Keep the ridge regression regularization parameter at 1, and set LinUCB's $\\alpha$ parameter to 2.\n",
        "Save these upper bounds to a file \"bounds.tsv\" with columns recipe_slug and score_bound."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "kY7aWD_PuP0W"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved LinUCB upper bounds to bounds.tsv with 100 recipes\n",
            "\n",
            "First 10 bounds:\n",
            "                    recipe_slug  score_bound\n",
            "0                       falafel     1.863465\n",
            "1                    spamburger     1.934742\n",
            "2              bacon-fried-rice     1.920721\n",
            "3               chicken-fingers     1.885462\n",
            "4                   apple-crisp     1.866724\n",
            "5         cranberry-apple-crisp     1.860560\n",
            "6  bacon-chocolate-chip-cookies     1.971459\n",
            "7                        sujebi     1.869244\n",
            "8               pasta-primavera     1.831731\n",
            "9                         ramen     2.405777\n",
            "\n",
            "Bound statistics:\n",
            "count    100.000000\n",
            "mean       2.279328\n",
            "std        0.207047\n",
            "min        1.831731\n",
            "25%        2.160796\n",
            "50%        2.284940\n",
            "75%        2.369329\n",
            "max        2.837011\n",
            "Name: score_bound, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "features = pd.read_csv('features.tsv', sep='\\t')\n",
        "ratings = pd.read_csv('ratings.tsv', sep='\\t')\n",
        "model = pd.read_csv('model.tsv', sep='\\t')\n",
        "\n",
        "assert (features['recipe_slug'] == ratings['recipe_slug']).all(), \"Recipe slugs must be aligned!\"\n",
        "\n",
        "X = features.drop(columns='recipe_slug').values\n",
        "y = ratings['rating'].values\n",
        "\n",
        "ridge_lambda = 1.0\n",
        "\n",
        "linucb_alpha = 2.0\n",
        "\n",
        "d = X.shape[1]\n",
        "\n",
        "A = X.T @ X + ridge_lambda * np.eye(d)\n",
        "\n",
        "A_inv = np.linalg.inv(A)\n",
        "\n",
        "theta = A_inv @ X.T @ y\n",
        "\n",
        "score_bounds = []\n",
        "\n",
        "for i in range(len(X)):\n",
        "    x_i = X[i]\n",
        "    \n",
        "    estimate = x_i @ theta\n",
        "    \n",
        "    uncertainty = linucb_alpha * np.sqrt(x_i @ A_inv @ x_i)\n",
        "    \n",
        "    upper_bound = estimate + uncertainty\n",
        "    score_bounds.append(upper_bound)\n",
        "\n",
        "bounds = pd.DataFrame({\n",
        "    'recipe_slug': features['recipe_slug'],\n",
        "    'score_bound': score_bounds\n",
        "})\n",
        "\n",
        "bounds.to_csv('bounds.tsv', sep='\\t', index=False)\n",
        "\n",
        "print(f\"Saved LinUCB upper bounds to bounds.tsv with {len(bounds)} recipes\")\n",
        "print(f\"\\nFirst 10 bounds:\")\n",
        "print(bounds.head(10))\n",
        "print(f\"\\nBound statistics:\")\n",
        "print(bounds['score_bound'].describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQ4RPppFvG-S"
      },
      "source": [
        "Submit \"bounds.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfazOSWlwYsP"
      },
      "source": [
        "## Part 6: Make Online Recommendations\n",
        "\n",
        "Implement LinUCB to make 100 recommendations starting with no data and using the same parameters as in part 5.\n",
        "One recommendation should be made at a time and you can break ties arbitrarily.\n",
        "After each recommendation, use the rating from part 1 as the reward to update the LinUCB data.\n",
        "Record the recommendations made in a file \"recommendations.tsv\" with columns \"recipe_slug\", \"score_bound\", and \"reward\".\n",
        "The rows in this file should be in the same order as the recommendations were made."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "hQ7r45B7wm4v"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Made 10 recommendations...\n",
            "Made 20 recommendations...\n",
            "Made 30 recommendations...\n",
            "Made 40 recommendations...\n",
            "Made 50 recommendations...\n",
            "Made 60 recommendations...\n",
            "Made 70 recommendations...\n",
            "Made 80 recommendations...\n",
            "Made 90 recommendations...\n",
            "Made 100 recommendations...\n",
            "\n",
            "Saved 100 recommendations to recommendations.tsv\n",
            "\n",
            "First 10 recommendations:\n",
            "        recipe_slug  score_bound  reward\n",
            "0     apple-crumble     7.483315     0.5\n",
            "1     ma-la-chicken     7.225922     0.5\n",
            "2       quesadillas     7.215690     0.5\n",
            "3             ramen     7.205736     0.5\n",
            "4  pain-au-chocolat     6.948626     1.0\n",
            "5   chocolate-babka     6.998701     1.0\n",
            "6        spamburger     7.010668     0.0\n",
            "7  bacon-fried-rice     6.981256     0.0\n",
            "8       nacho-fries     6.732809     0.5\n",
            "9   cranberry-sauce     6.672025     0.5\n",
            "\n",
            "Reward statistics:\n",
            "count    100.000000\n",
            "mean       0.520000\n",
            "std        0.250454\n",
            "min        0.000000\n",
            "25%        0.500000\n",
            "50%        0.500000\n",
            "75%        0.500000\n",
            "max        1.000000\n",
            "Name: reward, dtype: float64\n",
            "\n",
            "Cumulative reward: 52.00\n",
            "Average reward: 0.5200\n"
          ]
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "\n",
        "features = pd.read_csv('features.tsv', sep='\\t')\n",
        "ratings = pd.read_csv('ratings.tsv', sep='\\t')\n",
        "\n",
        "assert (features['recipe_slug'] == ratings['recipe_slug']).all(), \"Recipe slugs must be aligned!\"\n",
        "\n",
        "X = features.drop(columns='recipe_slug').values\n",
        "y = ratings['rating'].values\n",
        "recipe_slugs = features['recipe_slug'].values\n",
        "\n",
        "ridge_lambda = 1.0\n",
        "linucb_alpha = 2.0\n",
        "n_recommendations = 100\n",
        "d = X.shape[1] \n",
        "\n",
        "A = ridge_lambda * np.eye(d)  \n",
        "b = np.zeros(d)  # b = 0\n",
        "\n",
        "recommendations = []\n",
        "recommended_indices = set()\n",
        "\n",
        "for t in range(n_recommendations):\n",
        "    A_inv = np.linalg.inv(A)\n",
        "    \n",
        "    theta = A_inv @ b\n",
        "    \n",
        "    best_ucb = -np.inf\n",
        "    best_idx = None\n",
        "    \n",
        "    for i in range(len(X)):\n",
        "        if i in recommended_indices:\n",
        "            continue\n",
        "        \n",
        "        x_i = X[i]\n",
        "        estimate = x_i @ theta\n",
        "        uncertainty = linucb_alpha * np.sqrt(x_i @ A_inv @ x_i)\n",
        "        ucb = estimate + uncertainty\n",
        "        \n",
        "        if ucb > best_ucb:\n",
        "            best_ucb = ucb\n",
        "            best_idx = i\n",
        "    \n",
        "    recommended_indices.add(best_idx)\n",
        "    x_chosen = X[best_idx]\n",
        "    reward = y[best_idx]\n",
        "    \n",
        "    recommendations.append({\n",
        "        'recipe_slug': recipe_slugs[best_idx],\n",
        "        'score_bound': best_ucb,\n",
        "        'reward': reward\n",
        "    })\n",
        "    \n",
        "    A += np.outer(x_chosen, x_chosen)  \n",
        "    b += reward * x_chosen  \n",
        "    \n",
        "    if (t + 1) % 10 == 0:\n",
        "        print(f\"Made {t + 1} recommendations...\")\n",
        "\n",
        "recommendations_df = pd.DataFrame(recommendations)\n",
        "\n",
        "recommendations_df.to_csv('recommendations.tsv', sep='\\t', index=False)\n",
        "\n",
        "print(f\"\\nSaved {len(recommendations_df)} recommendations to recommendations.tsv\")\n",
        "print(f\"\\nFirst 10 recommendations:\")\n",
        "print(recommendations_df.head(10))\n",
        "print(f\"\\nReward statistics:\")\n",
        "print(recommendations_df['reward'].describe())\n",
        "print(f\"\\nCumulative reward: {recommendations_df['reward'].sum():.2f}\")\n",
        "print(f\"Average reward: {recommendations_df['reward'].mean():.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23jv0cD0woSt"
      },
      "source": [
        "Submit \"recommendations.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zi8lV2pbvWMs"
      },
      "source": [
        "## Part 7: Acknowledgments\n",
        "\n",
        "Make a file \"acknowledgments.txt\" documenting any outside sources or help on this project.\n",
        "If you discussed this assignment with anyone, please acknowledge them here.\n",
        "If you used any libraries not mentioned in this module's content, please list them with a brief explanation what you used them for.\n",
        "If you used any generative AI tools, please add links to your transcripts below, and any other information that you feel is necessary to comply with the generative AI policy.\n",
        "If no acknowledgements are appropriate, just write none in the file.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuNJe62UxCoH"
      },
      "source": [
        "Submit \"acknowledgments.txt\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smsTLuFcvR-I"
      },
      "source": [
        "## Part 8: Code\n",
        "\n",
        "Please submit a Jupyter notebook that can reproduce all your calculations and recreate the previously submitted files.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cgzHyF7wxpr"
      },
      "source": [
        "Submit \"project.ipynb\" in Gradescope."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": false
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
